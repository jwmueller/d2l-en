# Overview of the Machine Learning Pipeline
:label:`sec_pipeline_overview`

Leveraging supervised learning in practice involves many steps beyond simply training a model.
A full ML pipeline typically involves at least the following steps:

* Data Engineering to ensure the data are formatted appropriately for supervised learning.
* Data Splitting to reserve certain fractions of the data for tuning or evaluation rather than model-training.
* Feature Engineering to encode domain knowledge about the problem-at-hand, such as what sort of patterns are likely to be highly predictive.
* Training Individual Models, where often multiple types of models with be trained/tested for a particular dataset.
* Hyperparamer Tuning in order to ensure the miscellaneous configurations for each model are appropriately specified.
* Model Selection or Ensembling to determine which model or combination of multiple models will be most accurate on future data.
* Deployment of the model such that it is available to make predictions on new data.



### Deep Learning vs. Classical ML Pipeline

Aspects of Deep Learning Pipeline that Differ from Classical ML Pipeline:
transfer learning, data augmentation, many more hyperparameters to tune

### General Data Preprocessing vs Model-specific Data Preprocessing

### Training individual models

early stopping

### Refitting trained models to full training + validation data


## Summary


## Exercises

